{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09495b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a5fd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Load the data \n",
    "Weekly = load_data('Weekly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f2ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Methods\n",
    "log_reg = LogisticRegression()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3246d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Best predictors: ('Lag2',)\n",
      "Best Accuracy: 0.625\n",
      "Best Confusion Matrix:\n",
      "[[ 9 34]\n",
      " [ 5 56]]\n"
     ]
    }
   ],
   "source": [
    "# (j) Experiment with different combinations of predictors for each method\n",
    "from itertools import combinations\n",
    "\n",
    "best_accuracy = 0\n",
    "best_cm = None\n",
    "best_model = None\n",
    "best_predictors = None\n",
    "\n",
    "# Experimenting with different combinations of predictors\n",
    "for num_predictors in range(1, len(Weekly.columns) - 2):\n",
    "    for predictors in combinations(Weekly.columns[1:-2], num_predictors):\n",
    "        X_train = train_data[list(predictors)]\n",
    "        X_test = test_data[list(predictors)]\n",
    "\n",
    "        # Logistic Regression\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred_test = log_reg.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        if accuracy_test > best_accuracy:\n",
    "            best_accuracy = accuracy_test\n",
    "            best_cm = confusion_matrix(y_test, y_pred_test)\n",
    "            best_model = \"Logistic Regression\"\n",
    "            best_predictors = predictors\n",
    "\n",
    "        # LDA\n",
    "        lda.fit(X_train, y_train)\n",
    "        y_pred_test_lda = lda.predict(X_test)\n",
    "        accuracy_test_lda = accuracy_score(y_test, y_pred_test_lda)\n",
    "        if accuracy_test_lda > best_accuracy:\n",
    "            best_accuracy = accuracy_test_lda\n",
    "            best_cm = confusion_matrix(y_test, y_pred_test_lda)\n",
    "            best_model = \"LDA\"\n",
    "            best_predictors = predictors\n",
    "\n",
    "        # QDA\n",
    "        qda.fit(X_train, y_train)\n",
    "        y_pred_test_qda = qda.predict(X_test)\n",
    "        accuracy_test_qda = accuracy_score(y_test, y_pred_test_qda)\n",
    "        if accuracy_test_qda > best_accuracy:\n",
    "            best_accuracy = accuracy_test_qda\n",
    "            best_cm = confusion_matrix(y_test, y_pred_test_qda)\n",
    "            best_model = \"QDA\"\n",
    "            best_predictors = predictors\n",
    "\n",
    "        # KNN with K=1\n",
    "        for k in range(1, 11):  # Trying K values from 1 to 10\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred_test_knn = knn.predict(X_test)\n",
    "            accuracy_test_knn = accuracy_score(y_test, y_pred_test_knn)\n",
    "            if accuracy_test_knn > best_accuracy:\n",
    "                best_accuracy = accuracy_test_knn\n",
    "                best_cm = confusion_matrix(y_test, y_pred_test_knn)\n",
    "                best_model = \"KNN\"+k\n",
    "                best_predictors = predictors\n",
    "\n",
    "        # Naive Bayes\n",
    "        nb.fit(X_train, y_train)\n",
    "        y_pred_test_nb = nb.predict(X_test)\n",
    "        accuracy_test_nb = accuracy_score(y_test, y_pred_test_nb)\n",
    "        if accuracy_test_nb > best_accuracy:\n",
    "            best_accuracy = accuracy_test_nb\n",
    "            best_cm = confusion_matrix(y_test, y_pred_test_nb)\n",
    "            best_model = \"Naive Bayes\"\n",
    "            best_predictors = predictors\n",
    "\n",
    "print(\"Best model:\", best_model)\n",
    "print(\"Best predictors:\", best_predictors)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931d0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
